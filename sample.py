import subprocess
import random
import os
from tqdm import tqdm
from glob import glob
from typing import List,Dict
from extract import read_jsonl,write_list_to_jsonl

FILE_DICT = {
    "docvqa": "/perception-hl/neos.yan/l1_jsonls/add_size/docvqa_en.jsonl",
    "chartqa": "/perception-hl/neos.yan/l1_jsonls/add_size/chartqa_en.jsonl",
    "info_vqa": "/lustre/yexun.zhang/datasets_external/OCR/InfoVQA/train_wo_ocr_processed.jsonl",
    "RefCOCO+": "/lustre/MLM_evaluator/data/RefCOCO/jsonls_normalize_0-1000/refcoco+_train.jsonl",
    "textvqa": "/lustre/yexun.zhang/datasets_external/OCR/textvqa/textvqa_train_v1.0_processed.jsonl",
    "refcocog": "/lustre/MLM_evaluator/data/RefCOCO/jsonls_normalize_0-1000/refcocog_train.jsonl",
    "refcoco": "/lustre/MLM_evaluator/data/RefCOCO/jsonls_normalize_0-1000/refcoco_train.jsonl",
}



def count_lines_with_percentage() -> Dict:
    sample_percentage = {}
    line_counts = {}
    for name, path in FILE_DICT.items():
        try:
            result = subprocess.run(
                ['wc', '-l', path],
                capture_output=True,
                text=True,
                check=True
            )
          
            line_count = int(result.stdout.strip().split()[0])
            line_counts[name] = line_count
        except Exception as e:
            print(f"âš ï¸  {name} ç»Ÿè®¡å¤±è´¥: {str(e)}")
            line_counts[name] = 0  

    total_lines = sum(line_counts.values())
    if total_lines == 0:
        print("\nâŒ æ‰€æœ‰æ–‡ä»¶ç»Ÿè®¡å¤±è´¥ï¼Œæ— æ³•è®¡ç®—ç™¾åˆ†æ¯”")
        return


    print("\nğŸ“Š å„æ–‡ä»¶è¡Œæ•°åŠå æ¯”ï¼š")
    # æ’åºï¼ˆæŒ‰è¡Œæ•°é™åºï¼‰
    sorted_items = sorted(line_counts.items(), key=lambda x: x[1], reverse=True)
    for name, count in sorted_items:
        if count == 0:
            percentage = 0.0
        else:
            percentage = (count / total_lines) 
        sample_percentage[name] = percentage
        print(f"{name:10}  nums: {count}  å æ¯”: {percentage*100:.2f}%")

    print(f"\nğŸ“ æ€»è¡Œæ•°: {total_lines:,}")
    return sample_percentage



def make_sample_benchmark(total_nums:int, save_dir:str, file_dict:Dict,sample_percentage:Dict):
    for file_name,path in tqdm(file_dict.items()):
        # 1.è®¡ç®—é‡‡æ ·æ•°é‡
        percentage = sample_percentage[file_name]
        data = read_jsonl(path)
        sample_num = min(int(total_nums*percentage),len(data))

        # 2.é‡‡æ ·å¹¶å¯¹image è¿›è¡Œå¤„ç†
        sample_data = random.sample(data,sample_num)
        sample_data = [process_image_field(file_name,item,path) for item in sample_data]

        # 3.å†™å…¥æ–‡ä»¶
        save_path = os.path.join(save_dir,f'{file_name}.jsonl')
        # write_list_to_jsonl(sample_data,save_path)
        print(f'{file_name} sampled {sample_num}, saved to: {save_path}')

def mutliqa_to_single(input_file:str, output_file:str):
    data = read_jsonl(input_file)
    single_turn_datas = []
    for item in tqdm(data):
        conversations = item.get('conversations', [])
        if len(conversations) < 2 or len(conversations) % 2 != 0:
                    continue

         # æ‹†åˆ†å¤šè½®å¯¹è¯ä¸ºå•è½®ï¼ˆæ¯2ä¸ªå…ƒç´ ä¸ºä¸€è½®ï¼šhumanâ†’gptï¼‰
        for turn_idx in range(0, len(conversations), 2):
            # æå–å½“å‰è½®çš„humanå’Œgptå¯¹è¯
            human_turn = conversations[turn_idx]
            gpt_turn = conversations[turn_idx + 1]
            
            # éªŒè¯è§’è‰²æ˜¯å¦æ­£ç¡®ï¼ˆhumanåœ¨å‰ï¼Œgptåœ¨åï¼‰
            if human_turn.get('from') != 'human' or gpt_turn.get('from') != 'gpt':
                print(f"è­¦å‘Šï¼šç¬¬{line_num}è¡Œç¬¬{turn_idx//2 + 1}è½®è§’è‰²å¼‚å¸¸ï¼Œè·³è¿‡è¯¥è½®")
                continue
            
            # æ„å»ºå•è½®å¯¹è¯æ•°æ®ï¼ˆä¿ç•™åŸæ•°æ®çš„å…¶ä»–å­—æ®µï¼Œä»…æ›¿æ¢conversationsï¼‰
            single_turn_data = {
                **item,  # å¤åˆ¶idã€imageã€widthç­‰å…¶ä»–å­—æ®µ
                # 'id': f"{item['id']}_{turn_idx//2}",  # ç”Ÿæˆæ–°idï¼ˆåŸid_è½®æ¬¡ï¼‰
                "uuid" : f"{item['uuid']}_{turn_idx//2}",
                'conversations': [human_turn, gpt_turn]  # å½“å‰å•è½®å¯¹è¯
            }
            single_turn_datas.append(single_turn_data)
    write_list_to_jsonl(single_turn_datas,output_file)
          




def process_image_field(key, data_item, file_path):
    tdata = data_item
    if key in ['chartqa', 'docvqa', 'blip3-ocr-004', 'vqa-nle-llava-short', 
               "chartqapro", "deepform", "tatdqa", "robut_sqa_cauldron", 
               "chrome_writing", "ch_ocr", "MMK12", "MMMath", 
               "mavis-math-metagen", "puzzleVQA", "VisualPuzzle", 
               "Hyperphantasia", "COLUMBUS", "VisualSphinx-V1-Raw", 
               "SciVQA", "pr1"]:
        pass 
    
    elif key in ['info_vqa', "textvqa"]:
        tdata['image'] = os.path.join(os.path.dirname(file_path), tdata['image']['UNKNOWN'][0])
        
    elif key in ['RefCOCO+', 'ai2d_train_12k', "refcoco", "refcocog"]:
        tdata['image'] = tdata['image']['UNKNOWN'][0]

    return tdata

if __name__ == "__main__":
    print("å¼€å§‹ç»Ÿè®¡JSONLæ–‡ä»¶è¡Œæ•°åŠç™¾åˆ†æ¯”...")
    sample_percentage = count_lines_with_percentage()
    print("\nç»Ÿè®¡å®Œæˆ")
    print(sample_percentage)

    total_sum = 40000
    save_dir = '/home/fangdong.wang/mlm-evaluator/tools/mcts_cot_v2/data/sample_data_0915'
    # if not os.path.exists(save_dir):
    #     os.mkdir(save_dir)
    make_sample_benchmark(total_sum,save_dir,FILE_DICT,sample_percentage)
    files = glob(os.path.join(save_dir,'*.jsonl'))
    print(files)

    # input_file = '/home/fangdong.wang/mlm-evaluator/tools/mcts_cot_v2/data/sample_data_0915/info_vqa.jsonl'
    # output_file = '/home/fangdong.wang/mlm-evaluator/tools/mcts_cot_v2/data/sample_data_0915/info_vqa_single.jsonl'
    # mutliqa_to_single(input_file,output_file)